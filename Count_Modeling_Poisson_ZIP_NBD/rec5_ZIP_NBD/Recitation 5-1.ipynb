{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABA: Recitation 5\n",
    "\n",
    "### Spring 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import poisson\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediction in poisson\n",
    "- NBD\n",
    "- Zero Inflated Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household Needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "International agencies use household size to determine the magnitude of the household needs. I am attaching a dataset on a survey from Philippines which contains information on:\n",
    "\n",
    "- the region,\n",
    "- the number of people living in the household,\n",
    "- age of the head of the household,\n",
    "- number of children below age 5 and \n",
    "- type of roof used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, we aggregate the data by 5-year age cohort and find the mean and the variance of the number of people in the household in each cohort. This should help you understand whether your assumption of mean = variance is a reasonable one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df_q1 = pd.read_excel('household_data.xlsx',sheet_name='household')\n",
    "df_q1.rename(columns={'total_households':'total_household_size'},inplace=True)\n",
    "cols_to_keep = ['location','age','total_household_size','roof']\n",
    "df_q1 = df_q1[cols_to_keep].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1.groupby('location').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distribution of counts\n",
    "sns.histplot(data=df_q1,x='total_household_size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the minimum and maximum age\n",
    "min_age = df_q1.age.min() #18\n",
    "max_age = df_q1.age.max() #98\n",
    "\n",
    "# define the size of each bin\n",
    "bin_size = 5\n",
    "\n",
    "# generate the bin edges\n",
    "bin_edges = range(min_age-1,(max_age+bin_size),bin_size)\n",
    "\n",
    "# create the age groups by applying the pd.cut function\n",
    "df_q1['age_group'] = pd.cut(df_q1['age'], bins=bin_edges)\n",
    "\n",
    "# print the resulting dataframe\n",
    "df_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and variance for each cohort\n",
    "df_agg = df_q1.groupby('age_group')['total_household_size'].agg(['count','mean','std']).reset_index()\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean and variance are close in some cohorts, but not in others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In GLM, for Poisson model, your regress the mean of the counts log(y) with covariates in a linear fashion. \n",
    "We will plot log(mean of the size of household) with age. To do this we rely on our earlier calculation where you aggregated the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate by group and compute the log of the mean\n",
    "df_agg['age_group_bound'] = df_agg.age_group.apply(lambda x: x.left)\n",
    "df_agg['mean_log'] = np.log(df_agg['mean'])\n",
    "df_agg['age_group_str'] = df_agg.age_group.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot age groups against mean size of household\n",
    "sns.scatterplot(data=df_agg,x='age_group_bound',y='mean_log')\n",
    "plt.title(\"Mean count vs Age\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Mean Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We can also do it with the whole data\n",
    "# df_q1['age_group_bound'] = df_q1.age_group.apply(lambda x: x.left)\n",
    "# df_q1['log_hh_size'] = np.log(df_q1['total_household_size'])\n",
    "# df_q1['age_group_str'] = df_q1.age_group.astype('str')\n",
    "\n",
    "# sns.scatterplot(data=df_q1,x='age_group_bound',y='log_hh_size')\n",
    "# plt.title(\"Log Household Size vs Age\")\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Log Household Size')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear assumption between age group and log($\\lambda$) does not seem to hold. The log($\\lambda$) seems to follow a non linear pattern. Increasing with age up until the mid 40s, and then starts decreasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we estimate the Poisson model. First we include age and location dummies as covariates. Then, we will add age$^2$ to deal with the non-linearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create age^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1['age2'] = np.power(df_q1.age,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1.groupby('location').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are estimating the mean size of the househole as a function of the covariates:\n",
    "\n",
    "\\begin{equation}\n",
    "\\log(\\lambda_i) = \\beta_0 + \\beta_1 \\times \\text{DavaoRegion} + \\beta_2 \\times \\text{IlocosRegion} + \\beta_3 \\times \\text{MetroManila} + \\beta_4 \\times \\text{Visayas} + \\beta_5 \\times \\text{age}\n",
    "\\end{equation}\n",
    "\n",
    "Where: \n",
    "\n",
    "\\begin{align*}\n",
    "\\lambda & \\text{ is the expected size of the household}, \\\\\n",
    "\\beta_0 & \\text{ is the intercept}, \\\\\n",
    "\\beta_1 - \\beta_4 & \\text{ are the coefficients for Location dummies}, \\\\\n",
    "\\beta_5 & \\text{ is the coefficient for the variable \"Age\"}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Note on estimation:\n",
    "\n",
    "Recall that the paramaters are found by maximizing the likelihood function.\n",
    "\n",
    "For the entire dataset:\n",
    "\n",
    "$$L(\\mathbf{y}; \\boldsymbol{\\lambda}) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda_i} \\lambda_i^{y_i}}{y_i!} $$\n",
    "\n",
    "the overall log-likelihood for the entire dataset is the sum of the individual log-likelihoods for each observation:\n",
    "\n",
    "$$\\log L(\\mathbf{y}; \\boldsymbol{\\lambda_i}) = \\sum_{i=1}^{n} (-\\lambda_i + y_i \\log(\\lambda_i) - \\log(y_i!))$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{y}$ is the vector of observed counts.\n",
    "- $\\boldsymbol{\\lambda}_{i}$ is the vector of expected size of household modeled as a function of the predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training and test data sets. \n",
    "np.random.seed(42)\n",
    "mask = np.random.rand(len(df_q1)) < 0.8\n",
    "df_train = df_q1[mask]\n",
    "df_test = df_q1[~mask]\n",
    "print('Training data set length='+str(len(df_train)))\n",
    "print('Testing data set length='+str(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1\n",
    "expr1 = 'total_household_size ~ age + location'\n",
    "print(\"Expresion: %s\" % expr1)\n",
    "\n",
    "y_train, X_train = dmatrices(expr1, df_train, return_type='dataframe')\n",
    "y_test, X_test1 = dmatrices(expr1, df_test, return_type='dataframe')\n",
    "\n",
    "#Using the statsmodels GLM class, we first train the Poisson regression model on the training data set.\n",
    "poisson_training_results1 = sm.GLM(endog=y_train\n",
    "                                    ,exog=X_train\n",
    "                                    ,family=sm.families.Poisson()).fit()\n",
    "print(poisson_training_results1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include $Age^2$ to deal with non-linearity of the data:\n",
    "    \n",
    "\\begin{equation}\n",
    "\\log(\\lambda_i) = \\beta_0 + \\beta_1 \\times \\text{DavaoRegion} + \\beta_2 \\times \\text{IlocosRegion} + \\beta_3 \\times \\text{MetroManila} + \\beta_4 \\times \\text{Visayas} + \\beta_5 \\times \\text{age} + \\beta_5 \\times \\text{age}^2\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "expr2 = 'total_household_size ~ age + location + age2'\n",
    "print(\"Expresion: %s\" % expr2)\n",
    "y_train, X_train = dmatrices(expr2, df_train, return_type='dataframe')\n",
    "y_test, X_test2 = dmatrices(expr2, df_test, return_type='dataframe')\n",
    "\n",
    "\n",
    "#Using the statsmodels GLM class, we first train the Poisson regression model on the training data set.\n",
    "poisson_training_results_2 = sm.GLM(endog=y_train\n",
    "                                    ,exog= X_train\n",
    "                                    ,family=sm.families.Poisson()).fit()\n",
    "print(poisson_training_results_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Intercept (-0.5043)**: The intercept represents the log of the expected count of total household size when all the predictor variables are 0. Since age and age2 can't really be 0 in this context, this value is more theoretical. For categorical variables, it's the baseline against which other categories are compared. Here, the baseline is the log of the expected total household size for the reference location (not explicitly mentioned but implied to be the one not listed among the location categories) and when age is 0. \n",
    "\n",
    "- **location[T.DavaoRegion] (-0.0012)**: Being in the Davao Region, compared to the baseline location, changes the log of the expected total household size by -0.0012. This effect is very small and not statistically significant (p-value: 0.984), suggesting that being in Davao Region does not significantly affect the total household size compared to the baseline.\n",
    "\n",
    "- **location[T.IlocosRegion] (0.0204)**: Being in the Ilocos Region, compared to the baseline location, changes the log of the expected total household size by 0.0204. This is also a small and not statistically significant effect (p-value: 0.735), indicating no significant difference in total household size for Ilocos Region compared to the baseline.\n",
    "\n",
    "- **location[T.MetroManila] (0.0694)**: Being in Metro Manila, compared to the baseline location, changes the log of the expected total household size by 0.0694. Though this coefficient is larger than for other regions, it is not statistically significant (p-value: 0.183), suggesting that being in Metro Manila does not significantly alter the expected total household size compared to the baseline.\n",
    "\n",
    "- **location[T.Visayas] (0.1063)**: Being in the Visayas, compared to the baseline location, increases the log of the expected total household size by 0.1063. This coefficient **is statistically significant** (p-value: 0.021), indicating a significant effect on the total household size for those in the Visayas compared to the baseline.\n",
    "\n",
    "- **age (0.0753)**: Each additional year of age increases the log of the expected total household size by 0.0753. This is a statistically significant effect (p-value < 0.001), meaning as age increases, the total household size is expected to increase.\n",
    "\n",
    "- **age2 (-0.0007)**: The squared term of age indicates a non-linear relationship between age and the log of the expected total household size. Each additional year squared decreases the log of the expected total household size by 0.0007. This effect is statistically significant (p-value < 0.001), suggesting that the increase in total household size with age diminishes as age increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with only age and location as covariate shows a significant negative coefficient, suggesting a negative association between age and houshold. An estimate -0.0047 suggest that when age goes up by a unit, the household size goes down by exp(-0.0047) or about half a percent.\n",
    "\n",
    "Once we add age$^2$, we observe that both age and age$^2$ have a significant coefficient. Now, age has a positive coefficient, and age$^2$ has a negative coefficient. This suggests that as people get older, the positive effect of age decreases (as the plot we did earlier suggests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example effect of age:\n",
    "def effect_age(age):\n",
    "    return 0.0753*age -0.0007*np.power(age,2)\n",
    "\n",
    "age_range = np.arange(18, 98+1)\n",
    "\n",
    "sns.lineplot(x=age_range,y=effect_age(age_range))\n",
    "sns.lineplot(x=age_range, y=[0]*len(age_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we expect heterogeneity?\n",
    "\n",
    "We can allow $\\lambda$ to be heterogeneous. In particular, it will follow a Gamma distribution. The likelihood (probability of observing the data) is then:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$f_m(y) = f\\left(y|\\lambda\\right) f(\\lambda)$$\n",
    "\n",
    "where $f\\left(y|\\lambda\\right)$ is the Poisson distribution (conditioned on $\\lambda$), and $f(\\lambda)$ is the distribution of $\\lambda$ (assumed to be gamma).\n",
    "\n",
    "It turns out that a mixture of Poisson $f(y|\\lambda)$ with gamma $f(\\lambda)$ leads to the widely used **negative binomial distribution (NBD)**. The probability distribution for the NBD is given by:\n",
    "$$P(y; p, r) = \\frac{(y + r - 1)!}{y! (r - 1)!} p^r (1 - p)^y$$\n",
    "where:\n",
    "- $y$ is the number of failures,\n",
    "- $r$ is the number of successes,\n",
    "- and $p$ is the probability of success.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the model in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value of counts as a function of the predictors:\n",
    "\n",
    "$$log(\\lambda) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p $$\n",
    "\n",
    "The variance of the Negative Binomial distribution in terms of $\\lambda$ (i.e  $E(Y|X)$) and the dispersion parameter $\\alpha$:\n",
    "\n",
    "$$\\text{Var}(Y|X) = \\lambda + \\alpha \\lambda^2$$\n",
    "\n",
    "In this formula:\n",
    "\n",
    "- The term $\\lambda$ is the mean (note it is also the variance in the case of a Poisson distribution).\n",
    "- The term $\\alpha \\lambda^2$ accounts for the extra variability (overdispersion) beyond what's expected in a Poisson distribution.\n",
    "\n",
    "\n",
    "***Note that the how $\\alpha = 0$ leads to Poisson***\n",
    "\n",
    "\n",
    "We estimate the parameters by doing Maximum Likelihood Estimation.\n",
    "\n",
    "Given the Negative Binomial parameterization used in Statsmodel:\n",
    "\n",
    "$$f(y; \\lambda, \\alpha) = \\frac{\\Gamma(y + \\frac{1}{\\alpha})}{y! \\Gamma(\\frac{1}{\\alpha})} \\left( \\frac{1}{1 + \\alpha \\lambda} \\right)^{\\frac{1}{\\alpha}} \\left( \\frac{\\alpha \\lambda}{1 + \\alpha \\lambda} \\right)^y $$\n",
    "\n",
    "Where:\n",
    "- $ y $ is the observed count.\n",
    "- $ \\lambda $ is the mean related to the predictors as: $ \\log(\\lambda) = X^T\\beta $\n",
    "- $ \\alpha $ is the dispersion parameter.\n",
    "\n",
    "The likelihood for observed data $( Y_1, Y_2, ..., Y_n)$ with predictors $ X_1, X_2, ..., X_n $ is:\n",
    "\n",
    "$$ L(\\beta, \\alpha | Y, X) = \\prod_{i=1}^{n} \\frac{\\Gamma(Y_i + \\frac{1}{\\alpha})}{Y_i! \\Gamma(\\frac{1}{\\alpha})} \\left( \\frac{1}{1 + \\alpha \\exp(X_i^T \\beta)} \\right)^{\\frac{1}{\\alpha}} \\left( \\frac{\\alpha \\exp(X_i^T \\beta)}{1 + \\alpha \\exp(X_i^T \\beta)} \\right)^{Y_i} $$\n",
    "\n",
    "Source: https://www.statsmodels.org/stable/generated/statsmodels.genmod.families.family.NegativeBinomial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We believe that data is heterogeneous and estimate the Negative Binomial Model with the age and location as covariates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create expression and dmatrices\n",
    "expr_nbd = 'total_household_size ~ age + location'\n",
    "y_train, X_train = dmatrices(expr_nbd, df_train, return_type='dataframe')\n",
    "y_test, X_test = dmatrices(expr_nbd, df_test, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit NBD model using Negative binomial\n",
    "NBD_training_results = sm.NegativeBinomial(endog=y_train\n",
    "                                           ,exog=X_train).fit()\n",
    "print(NBD_training_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Intercept (1.4920)**: The intercept represents the log of the expected count of the total household size when all predictor variables are at their reference levels (CentralLuzon). \n",
    "\n",
    "- **Location Coefficients**:\n",
    "  - **Davao Region (0.0117)**: Being in the Davao Region changes the log of the expected total household size by 0.0117 compared to the baseline location. However, this effect is not statistically significant (p-value: 0.867), suggesting that being in Davao Region does not significantly alter the expected total household size compared to the baseline.\n",
    "  - **Ilocos Region (0.0075)**: Being in the Ilocos Region changes the log of the expected total household size by 0.0075 compared to the baseline location. This effect is also not statistically significant (p-value: 0.916), indicating no significant difference in total household size for Ilocos Region compared to the baseline.\n",
    "  - **Metro Manila (0.0936)**: Being in Metro Manila changes the log of the expected total household size by 0.0936 compared to the baseline location. The effect is not statistically significant (p-value: 0.130), suggesting that being in Metro Manila does not significantly alter the expected total household size compared to the baseline.\n",
    "  - **Visayas (0.1248)**: Being in the Visayas increases the log of the expected total household size by 0.1248 compared to the baseline location. This coefficient **is statistically significant** (p-value: 0.023), indicating a significant effect on the total household size for those in the Visayas compared to the baseline.\n",
    "\n",
    "- **Age (-0.0049)**: Each additional year of age decreases the log of the expected total household size by -0.0049. This is a statistically significant effect (p-value < 0.000), meaning as age increases, the total household size is expected to decrease slightly.\n",
    "\n",
    "- **Alpha (0.1148)**: The alpha parameter in a Negative Binomial Regression model measures the degree of over-dispersion in the count data. A value of 0 would indicate that the data is not over-dispersed (i.e., a Poisson distribution is appropriate), while positive values indicate the presence of over-dispersion. Here, the statistically significant alpha (p-value < 0.000) suggests that there is over-dispersion in the total household size data, and the Negative Binomial model is a better fit than a Poisson model. In Poisson, mean=variance, and in the NBD model, variance = mean + alpha*mean2. The value of 0.1148 indicates the extent of over-dispersion, with higher values signifying more over-dispersion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you predict the outcome, what do you predict? We will plot the histogram of actual and predicted number of households. Why does the prediction doesn't match the data well?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict functions estimates the expected value of people in the household given the covariates:\n",
    "$$\\lambda_i = exp(\\beta_0 + \\beta_1 \\times \\text{DavaoRegion} + \\beta_2 \\times \\text{IlocosRegion} + \\beta_3 \\times \\text{MetroManila} + \\beta_4 \\times \\text{Visayas} + \\beta_5 \\times \\text{age}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1.491966+0.093585+75*-0.004935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBD PREDICTIONS\n",
    "nbd_hh_predicted_mean = NBD_training_results.predict(X_test)\n",
    "y_test['nbd_hh_predicted_mean'] = nbd_hh_predicted_mean\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Matplotlib figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Plot the 'nbd_hh_predicted_mean' histogram\n",
    "sns.histplot(data=y_test, x='nbd_hh_predicted_mean', color='red', binwidth=1, label='Predicted Means', alpha=0.5)\n",
    "\n",
    "# Plot the 'total_household_sizes' histogram\n",
    "sns.histplot(data=y_test, x='total_household_size', color='blue', binwidth=1, label='Number of people in the HH (actual)', alpha=0.5)\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the covariates do not explain the variation, individual level predictions collpase towards the mean. Hence, the predictions using the mean do not match the actual data well. Using the random number generators we get better predictions. We didn't discuss this in class, but you can use this as reference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the counts using the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just simulate one sample for each observation \n",
    "## use this as the prediction \n",
    "params = NBD_training_results.params\n",
    "gamma=np.exp(params[:-1]@ X_test.T) #exp(XB)\n",
    "alpha=np.exp(params[-1]) #alpha\n",
    "rng = np.random.default_rng()\n",
    "y_test['nbd_hh_random_draw'] = rng.negative_binomial(n=gamma,p=alpha/(1+alpha)) #n=exp(XB), p=(alpha/(1+alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Matplotlib figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Plot the 'nbd_hh_random_draw' histogram\n",
    "sns.histplot(data=y_test, x='nbd_hh_random_draw', color='red', binwidth=0.5, label='NBD Draws', alpha=0.5)\n",
    "\n",
    "# Plot the 'total_household_sizes' histogram\n",
    "sns.histplot(data=y_test, x='total_household_size', color='blue', binwidth=0.5, label='Number of people in the HH (actual)', alpha=0.5)\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Note on Zero Inflated Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero inflated model allows us to model data that has too many zero counts. To accommodate excessive zeros, we have to incorporate a structure which can predict probability of zero incidence. Thus, a Zero inflated Poisson model has two parts:\n",
    "\n",
    "- A PMF P(y_i=0) which is used to calculate the probability of observing a zero count.\n",
    "- A second PMF P(y_i=k) which is used to calculate the probability of observing k events, given that k > 0.\n",
    "\n",
    "We can express it as:\n",
    "\n",
    "$${\\displaystyle \\Pr(Y=0)=\\pi +(1-\\pi )e^{-\\lambda }}$$\n",
    "\n",
    "$${\\displaystyle \\Pr(Y=y_{i})=(1-\\pi ){\\frac {\\lambda ^{y_{i}}e^{-\\lambda }}{y_{i}!}},\\qquad y_{i}=1,2,3,...}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the outcome variable \n",
    "$y_{i}$ has any non-negative integer value, $\\lambda$  is the expected Poisson count for the  ith individual; $\\pi$  is the probability of extra zeros. (see https://en.wikipedia.org/wiki/Zero-inflated_model#Discrete_pseudo_compound_Poisson_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **Zero-Inflated Poisson (ZIP) model**:\n",
    "\n",
    "1. **Logistic Component (Inflation model)**:\n",
    "Given the probability:\n",
    "$$\\pi_i = \\frac{e^{X_i^T \\beta_{infl}}} {1 + e^{X_i^T \\beta_{infl}}}$$\n",
    "\n",
    "The log odds of an observation being in the \"always-zero\" group is:\n",
    "$$\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = X_i^T \\beta_{infl}$$\n",
    "Where:\n",
    "- $ \\log $ represents the natural logarithm.\n",
    "- $ \\pi_i $ is the probability that the i-th observation is always zero.\n",
    "- $ X_i $ is the vector of predictors for the i-th observation.\n",
    "- $ \\beta_{infl} $ are the coefficients for the logistic regression component, which you are estimating.\n",
    "\n",
    "2. **Poisson Component**:\n",
    "The mean $ \\lambda$ of the Poisson distribution (for observations not in the \"always-zero\" group) is modeled as:\n",
    "$$ \\log(\\lambda_i) = X_i^T \\beta_{pois} $$\n",
    "Where:\n",
    "- $\\beta_{pois}$ are the coefficients of the Poisson regression component.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using the Zero-Inflated Poisson model:\n",
    "\n",
    "1. **Conditional Expectation**: The expected count, taking both zero inflation and the count distribution into account.\n",
    "    ```python\n",
    "    expected_value = zip_training_results.predict(exog=X_test, exog_infl=X_test, which='mean')\n",
    "    ```\n",
    "\n",
    "2. **Linear Predictor**: The linear combination of predictors before applying any link or count function.\n",
    "    ```python\n",
    "    linear_predictor = zip_training_results.predict(exog=X_test, exog_infl=X_test, which='linear')\n",
    "    ```\n",
    "\n",
    "3. **Estimated Variance**: The variance of the response variable as implied by the model.\n",
    "    ```python\n",
    "        Didn't work\n",
    "    ```\n",
    "\n",
    "4. **Mean of Main Model**: The expected count only from the main count model, ignoring zero inflation.\n",
    "    ```python\n",
    "    mean_main = zip_training_results.predict(exog=X_test, which='mean-main')\n",
    "    ```\n",
    "\n",
    "5. **Probability of Main Model**: The probability that an observation comes from the main count model. The complementary probability represents zero inflation.\n",
    "    ```python\n",
    "    prob_main = zip_training_results.predict(exog=X_test, exog_infl=X_test, which='prob-main')\n",
    "    ```\n",
    "\n",
    "6. **Expected Value for Non-zero Counts**: The expected count given that it is not zero.\n",
    "    ```python\n",
    "    mean_nonzero = zip_training_results.predict(exog=X_test, which='mean-nonzero')\n",
    "    ```\n",
    "\n",
    "7. **Probability of Zero Count**: The probability that the count is zero. \n",
    "    ```python\n",
    "    prob_zero = zip_training_results.predict(exog=X_test, exog_infl=X_test, which='prob-zero')\n",
    "    ```\n",
    "\n",
    "8. **Probabilities for Each Count**: The probabilities for a range of count values.\n",
    "    ```python\n",
    "    Didn't work!\n",
    "    ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
